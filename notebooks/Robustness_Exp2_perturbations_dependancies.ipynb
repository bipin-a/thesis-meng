{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h4AZxW8yqrvr"
      ],
      "authorship_tag": "ABX9TyOfyyV/4LynAUJdDyzQtDIa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bipin-a/thesis-meng/blob/main/Robustness_Exp2_perturbations_dependancies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install textattack transformers sentence_transformers"
      ],
      "metadata": {
        "id": "n8z-zu5F0JrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bbF1_GM0EhP"
      },
      "outputs": [],
      "source": [
        "import transformers \n",
        "import textattack"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
        "from textattack.goal_functions import UntargetedClassification\n",
        "import pandas as pd\n",
        "\n",
        "from textattack.attack_recipes import (\n",
        "    TextFoolerJin2019,\n",
        "    HotFlipEbrahimi2017,\n",
        "    BAEGarg2019\n",
        ")\n",
        "from datasets import load_dataset\n"
      ],
      "metadata": {
        "id": "1-l02lCElPNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkYRTb3blNKR",
        "outputId": "09a1c541-41d9-4e1f-b793-5ed40b60d0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "perturbed_data_root = '/content/drive/MyDrive/meng_thesis/code/data/perturbed_data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfiTtuUOV5FQ",
        "outputId": "62ec540c-02db-4125-8232-ad50a170e8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 2: \n",
        "- Hypothesis: The perturbations of white box adversarial attacks dependant on the victim model.\n",
        "\n",
        "    1. Select white box adv attack \n",
        "    2. Select a dataset \n",
        "    3. Test a range of Victim Models\n",
        "    4. Generate list of perturbed datasets for each victim model\n",
        "    5. Compare overlap of inputs across lists datasets  \n",
        "    6. Repeat steps 1-6 with different white box adv attacks \n"
      ],
      "metadata": {
        "id": "Q4cRaLWUeXHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get huggingface models and tokenizer\n",
        "\n",
        "checkpoint_names = [\n",
        "    \"textattack/distilbert-base-uncased-imdb\",\n",
        "    \"textattack/albert-base-v2-imdb\",\n",
        "    \"textattack/roberta-base-imdb\"\n",
        "    ]\n",
        "model_names = [\n",
        "    'distilbert-base-uncased',\n",
        "    'albert-base-v2',\n",
        "    'roberta-base-imdb'\n",
        "    ]\n",
        "dataset_name = 'imdb'\n",
        "\n",
        "models = [transformers.AutoModelForSequenceClassification.from_pretrained(c) for c in checkpoint_names]\n",
        "tokenizers = [transformers.AutoTokenizer.from_pretrained(c) for c in checkpoint_names]\n",
        "model_wrappers = [HuggingFaceModelWrapper(m, t) for m,t in zip(models,tokenizers)]\n",
        "\n",
        "hg_dataset = load_dataset(dataset_name, split=\"test[:10]\") \n"
      ],
      "metadata": {
        "id": "WXhrFzIhPxWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = textattack.datasets.Dataset( [(i.get(\"text\") , i.get(\"label\")) for i in hg_dataset] )"
      ],
      "metadata": {
        "id": "El92xDV2gzvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(hg_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Q4LSt-PXhgNv",
        "outputId": "a75ec678-d569-41b5-f6f4-6d77b3bf6df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  I love sci-fi and am willing to put up with a ...      0\n",
              "1  Worth the entertainment value of a rental, esp...      0\n",
              "2  its a totally average film with a few semi-alr...      0\n",
              "3  STAR RATING: ***** Saturday Night **** Friday ...      0\n",
              "4  First off let me say, If you haven't enjoyed a...      0\n",
              "5  I had high hopes for this one until they chang...      0\n",
              "6  Isaac Florentine has made some of the best wes...      0\n",
              "7  It actually pains me to say it, but this movie...      0\n",
              "8  Technically I'am a Van Damme Fan, or I was. th...      0\n",
              "9  Honestly awful film, bad editing, awful lighti...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbbb9111-d84e-493a-9df7-a0d7972b2684\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love sci-fi and am willing to put up with a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Worth the entertainment value of a rental, esp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>its a totally average film with a few semi-alr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>First off let me say, If you haven't enjoyed a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I had high hopes for this one until they chang...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Isaac Florentine has made some of the best wes...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>It actually pains me to say it, but this movie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Technically I'am a Van Damme Fan, or I was. th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Honestly awful film, bad editing, awful lighti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbbb9111-d84e-493a-9df7-a0d7972b2684')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbbb9111-d84e-493a-9df7-a0d7972b2684 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbbb9111-d84e-493a-9df7-a0d7972b2684');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LWmrmepRhfG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "parallel_flag = bool(torch.cuda.device_count())\n",
        "parallel_flag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxJNpZwMlUYR",
        "outputId": "c8626478-c3c4-4157-c38c-d7144846586f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attacks = [\n",
        "    TextFoolerJin2019, \n",
        "    # HotFlipEbrahimi2017,\n",
        "    BAEGarg2019\n",
        "]\n",
        "\n",
        "attack_names = [\n",
        "    \"TextFoolerJin2019\", \n",
        "    # \"HotFlipEbrahimi2017\",\n",
        "    \"BAEGarg2019\"\n",
        "]"
      ],
      "metadata": {
        "id": "P2djgkYlyC0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for attack_model, attack_name in zip(attacks, attack_names):\n",
        "  for model_wrapper, model_name in zip(model_wrappers, model_names):\n",
        "    \n",
        "    print(model_name,attack_name)\n",
        "    attack = attack_model.build(model_wrapper)\n",
        "\n",
        "    attack_args = textattack.AttackArgs(\n",
        "        parallel = parallel_flag,\n",
        "        num_examples=5,\n",
        "        csv_coloring_style = 'html',\n",
        "        log_to_csv=f\"{perturbed_data_root}/{attack_name}{model_name}_html.csv\",\n",
        "        # checkpoint_interval=5,\n",
        "        # checkpoint_dir=\"checkpoints\",\n",
        "        disable_stdout=True\n",
        "    )\n",
        "\n",
        "    attacker = textattack.Attacker(attack, dataset, attack_args)\n",
        "    attacker.attack_dataset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0u-XYZJSFm0h",
        "outputId": "2addb72a-dd4b-41e3-d3fc-6f22fac7c333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "textattack: Logging to CSV at path /content/drive/MyDrive/meng_thesis/code/data/perturbed_data/TextFoolerJin2019distilbert-base-uncased_html.csv\n",
            "textattack: Running 1 worker(s) on 1 GPU(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distilbert-base-uncased TextFoolerJin2019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Worklist size: 5\n",
            "textattack: Worklist candidate size: 5\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 1 / 5: 100%|██████████| 5/5 [01:16<00:00, 15.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 4      |\n",
            "| Number of failed attacks:     | 0      |\n",
            "| Number of skipped attacks:    | 1      |\n",
            "| Original accuracy:            | 80.0%  |\n",
            "| Accuracy under attack:        | 0.0%   |\n",
            "| Attack success rate:          | 100.0% |\n",
            "| Average perturbed word %:     | 6.5%   |\n",
            "| Average num. words per input: | 215.6  |\n",
            "| Avg num queries:              | 546.75 |\n",
            "+-------------------------------+--------+"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "textattack: Unknown if model of class <class 'transformers.models.albert.modeling_albert.AlbertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "textattack: Logging to CSV at path /content/drive/MyDrive/meng_thesis/code/data/perturbed_data/TextFoolerJin2019albert-base-v2_html.csv\n",
            "textattack: Running 1 worker(s) on 1 GPU(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "albert-base-v2 TextFoolerJin2019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Worklist size: 5\n",
            "textattack: Worklist candidate size: 5\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5: 100%|██████████| 5/5 [02:58<00:00, 35.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+-------------------------------+---------+\n",
            "| Attack Results                |         |\n",
            "+-------------------------------+---------+\n",
            "| Number of successful attacks: | 3       |\n",
            "| Number of failed attacks:     | 0       |\n",
            "| Number of skipped attacks:    | 2       |\n",
            "| Original accuracy:            | 60.0%   |\n",
            "| Accuracy under attack:        | 0.0%    |\n",
            "| Attack success rate:          | 100.0%  |\n",
            "| Average perturbed word %:     | 10.04%  |\n",
            "| Average num. words per input: | 215.6   |\n",
            "| Avg num queries:              | 1112.67 |\n",
            "+-------------------------------+---------+"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "textattack: Unknown if model of class <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "textattack: Logging to CSV at path /content/drive/MyDrive/meng_thesis/code/data/perturbed_data/TextFoolerJin2019roberta-base-imdb_html.csv\n",
            "textattack: Running 1 worker(s) on 1 GPU(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "roberta-base-imdb TextFoolerJin2019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Worklist size: 5\n",
            "textattack: Worklist candidate size: 5\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  20%|██        | 1/5 [05:44<22:56, 344.05s/it]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ea6c0bceedba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mattacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttacker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mattacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/textattack/attacker.py\u001b[0m in \u001b[0;36mattack_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;34m\"Found no GPU on your system. To run attacks in parallel, GPU is required.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 )\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attack_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/textattack/attacker.py\u001b[0m in \u001b[0;36m_attack_parallel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_remaining_attacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_ncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mworklist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0mworklist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['distilbert-base-uncased','albert-base-v2']\n",
        "df1 = pd.read_csv(f\"{perturbed_data_root}/{model_names[0]}_html.csv\")[['original_text','perturbed_text']]\n",
        "df2 = pd.read_csv(f\"{perturbed_data_root}/{model_names[1]}_html.csv\")[['perturbed_text']]\n",
        "\n",
        "df1 = df1.rename(columns={'perturbed_text':'perturbed_text_distilbert-base'})\n",
        "df2 = df2.rename(columns={'perturbed_text':'perturbed_text_albert-base'})\n",
        "\n",
        "main = pd.concat([df1,df2],axis=1)"
      ],
      "metadata": {
        "id": "Z-hHk0oTLWUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main.head(2).to_markdown()"
      ],
      "metadata": {
        "id": "PNHMARGr5p2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TJprV0ux06O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjfPPCYSx03j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO:\n",
        "- Measure Perplexity and other metrics of the perturbed data"
      ],
      "metadata": {
        "id": "h4AZxW8yqrvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://huggingface.co/docs/transformers/perplexity"
      ],
      "metadata": {
        "id": "oGebSFKapNuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG4SSacaHFPA"
      },
      "outputs": [],
      "source": [
        "HG_datasets = {}\n",
        "dfs = {}\n",
        "\n",
        "for dataset_name in dataset_names:\n",
        "  df = pd.read_csv(f\"{root}/data/{dataset_name}.csv\")\n",
        "  _dataset = df[[\"perturbed_text\",\"ground_truth_output\"]]\n",
        "  dfs[dataset_name] = _dataset\n",
        "\n",
        "  _dataset = _dataset.rename({\"perturbed_text\":\"text\", \n",
        "                              \"ground_truth_output\":\"labels\"}\n",
        "                             ,axis=1)\n",
        "  \n",
        "  dataset = HG_Dataset.from_pandas(_dataset)\n",
        "  HG_datasets[dataset_name] = dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYKabXpisjYc",
        "outputId": "948c57f0-63d7-425c-95e3-4fc7751c3a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: 1    3000\n",
            "0    3000\n",
            "Name: ground_truth_output, dtype: int64\n",
            "name: 1    3000\n",
            "0    3000\n",
            "Name: ground_truth_output, dtype: int64\n",
            "name: 1    2002\n",
            "0    1998\n",
            "Name: ground_truth_output, dtype: int64\n",
            "name: 1    504\n",
            "0    496\n",
            "Name: ground_truth_output, dtype: int64\n",
            "name: 1    504\n",
            "0    496\n",
            "Name: ground_truth_output, dtype: int64\n",
            "name: 1    501\n",
            "0    499\n",
            "Name: ground_truth_output, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "for name, df in dfs.items():\n",
        "  print(f\"name: {df.ground_truth_output.value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g6Ai0pDqGFd"
      },
      "source": [
        "## textattack/bert-base-uncased-imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkmJX6VtOZnQ"
      },
      "outputs": [],
      "source": [
        "metric_results = {}\n",
        "\n",
        "for hg_name in HG_datasets:\n",
        "  for checkpoint_name in checkpoint_names:\n",
        "\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    dataset = HG_datasets[hg_name]\n",
        "    print(checkpoint_name, hg_name)\n",
        "\n",
        "    clf_metrics = evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"])\n",
        "\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(checkpoint_name)\n",
        "    model_tokenizer = transformers.AutoTokenizer.from_pretrained(checkpoint_name)\n",
        "    model.to(device)\n",
        "\n",
        "    tokenized_datasets_all = dataset.map(\n",
        "        lambda examples : model_tokenizer(examples[\"text\"], \n",
        "                                  padding=\"max_length\",\n",
        "                                  truncation=True)\n",
        "        )\n",
        "    \n",
        "    tokenized_datasets = tokenized_datasets_all.remove_columns(['text'])\n",
        "    tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "    test_dataloader = DataLoader(tokenized_datasets,\n",
        "                              shuffle=True, \n",
        "                              batch_size=8)\n",
        "\n",
        "    model.eval()\n",
        "    for batch in test_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        clf_metrics.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    m_res = clf_metrics.compute()\n",
        "    print(m_res)\n",
        "\n",
        "    metric_results[(hg_name,checkpoint_name)] = m_res\n",
        "    print(\"\\n \\n \")\n"
      ]
    }
  ]
}